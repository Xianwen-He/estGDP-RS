{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pca(X, components = 3):\n",
    "    '''\n",
    "    first = True\n",
    "    for images in X:\n",
    "        if first:\n",
    "            train_for_pca = images\n",
    "            first = False\n",
    "        else:\n",
    "            # print(train_for_pca.shape)\n",
    "            train_for_pca = np.concatenate([train_for_pca, images])    \n",
    "    '''\n",
    "    train_for_pca = X\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_for_pca)\n",
    "    train_for_pca=scaler.transform(train_for_pca)\n",
    "    pca = PCA(n_components = components)\n",
    "    pca.fit(train_for_pca)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensional_reduction(X, pca):\n",
    "    reduced_X = []\n",
    "    for images in X:\n",
    "        train_pca = pca.transform(images)\n",
    "        train_x = np.append(np.concatenate([np.mean(train_pca, axis = 0), np.std(train_pca, axis = 0)]), len(images))\n",
    "        colnum = train_pca.shape[1]\n",
    "        for subset in itertools.combinations(range(colnum), 2):\n",
    "            train_x = np.append(train_x, np.corrcoef(train_pca[:, subset[0]], train_pca[:, subset[1]])[0][1])\n",
    "            \n",
    "        reduced_X.append(train_x)        \n",
    "    reduced_X = np.array(reduced_X)\n",
    "    return reduced_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_res(dimension, X, X1, y, y1, PAC, PAC1):\n",
    "    X_ = np.concatenate(X)\n",
    "    \n",
    "    # 训练降维器\n",
    "    pca = train_pca(X_, components = dimension)\n",
    "    \n",
    "    # 降维并提取特征\n",
    "    reduced_trainX = dimensional_reduction(X, pca)\n",
    "    reduced_validX = dimensional_reduction(X1, pca)\n",
    "\n",
    "    # 去掉空值\n",
    "    yt = np.delete(y, np.where(~np.isnan(reduced_trainX).any(axis=1) == False))\n",
    "    y1v = np.delete(y1, np.where(~np.isnan(reduced_validX).any(axis=1) == False))\n",
    "    PACt = np.delete(PAC, np.where(~np.isnan(reduced_trainX).any(axis=1) == False))\n",
    "    PAC1v = np.delete(PAC1, np.where(~np.isnan(reduced_validX).any(axis=1) == False))\n",
    "    reduced_trainX = reduced_trainX[~np.isnan(reduced_trainX).any(axis=1), :]\n",
    "    reduced_validX = reduced_validX[~np.isnan(reduced_validX).any(axis=1), :]\n",
    "    \n",
    "    return reduced_trainX, reduced_validX, yt, y1v, PACt, PAC1v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_r2(model, tX, tY, vX, vY):\n",
    "    model.fit(tX, tY)\n",
    "    vy_pred = model.predict(vX)\n",
    "    return r2_score(vY, vy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入原始数据\n",
    "data = pd.read_csv('Data/2017_features.csv')\n",
    "data = data.dropna()\n",
    "#data = data[data['features']!='adsadas']\n",
    "label = pd.read_csv('Data/PAC_GDP17.csv')\n",
    "data = pd.merge(data, label, how='left')\n",
    "X = []\n",
    "y = []\n",
    "PAC = []\n",
    "for i in data.index:\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    #try:\n",
    "    x_i = [float(x) for x in re.split(r', |\\[|\\]', data['features'].loc[i]) if len(x) > 0]\n",
    "    x_i = np.array(x_i).reshape(-1, 4096)\n",
    "    X.append(x_i)\n",
    "    y.append(data['GDP'].loc[i])\n",
    "    PAC.append(data['PAC'].loc[i])\n",
    "    #except:\n",
    "       # print('error')\n",
    "zeros = [X.index(x) for x in X if x.shape[0] == 0]\n",
    "X = np.delete(np.array(X), zeros)\n",
    "y = np.delete(np.array(y), zeros)\n",
    "PAC = np.delete(np.array(PAC), zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入2018年数据\n",
    "data1 = pd.read_csv('Data/2018_features.csv')\n",
    "data1 = data1.dropna()\n",
    "label1 = pd.read_csv('Data/PAC_GDP18.csv')\n",
    "data1 = pd.merge(data1, label1, how='left')\n",
    "X1 = []\n",
    "y1 = []\n",
    "PAC1 = []\n",
    "for i in data1.index:\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    #try:\n",
    "    x_i = [float(x) for x in re.split(r', |\\[|\\]', data1['features'].loc[i]) if len(x) > 0]\n",
    "    x_i = np.array(x_i).reshape(-1, 4096)\n",
    "    X1.append(x_i)\n",
    "    y1.append(data1['GDP'].loc[i])\n",
    "    PAC1.append(data1['PAC'].loc[i])\n",
    "    #except:\n",
    "       # print('error')\n",
    "zeros1 = [X1.index(x) for x in X1 if x.shape[0] == 0]\n",
    "X1 = np.delete(np.array(X1), zeros1)\n",
    "y1 = np.delete(np.array(y1), zeros1)\n",
    "PAC1 = np.delete(np.array(PAC1), zeros1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgel = []\n",
    "ridgel2 = []\n",
    "lassol = []\n",
    "lassol2 = []\n",
    "rfl = []\n",
    "rfl2 = []\n",
    "gbll = []\n",
    "gbll2 = []\n",
    "gbtl = []\n",
    "gbtl2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_range = [i for i in range(3, 26, 1)]\n",
    "for d in range(3, 26, 1):\n",
    "    ### 降维\n",
    "    print('=======', d, '=======')\n",
    "    reduced_trainX, reduced_validX, yt, y1v, PACt, PAC1v = pca_res(d, X, X1, y, y1, PAC, PAC1)\n",
    "    \n",
    "    ### 特征构造\n",
    "    poly = PolynomialFeatures(interaction_only = False, include_bias = False)\n",
    "    tX_interact = poly.fit_transform(reduced_trainX)\n",
    "    vX_interact = poly.fit_transform(reduced_validX)\n",
    "    \n",
    "    ### ridge\n",
    "    ridgel.append(regr_r2(Ridge(), reduced_trainX, np.log(yt), reduced_validX, np.log(y1v)))\n",
    "    ridgel2.append(regr_r2(Ridge(), tX_interact, np.log(yt), vX_interact, np.log(y1v)))\n",
    "    print('ridge:', ridgel[-1], ridgel2[-1])\n",
    "    \n",
    "    ### lasso\n",
    "    lassol.append(regr_r2(Lasso(), reduced_trainX, np.log(yt), reduced_validX, np.log(y1v)))\n",
    "    lassol2.append(regr_r2(Lasso(), tX_interact, np.log(yt), vX_interact, np.log(y1v)))\n",
    "    print('lasso:', lassol[-1], lassol2[-1])\n",
    "    \n",
    "    ### random forest\n",
    "    RandomForestRegressor(n_estimators=10)\n",
    "    rfl.append(regr_r2(RandomForestRegressor(n_estimators=10), reduced_trainX, np.log(yt), reduced_validX, np.log(y1v)))\n",
    "    rfl2.append(regr_r2(RandomForestRegressor(n_estimators=10), tX_interact, np.log(yt), vX_interact, np.log(y1v)))\n",
    "    print('random forest:', rfl[-1], rfl2[-1])\n",
    "    \n",
    "    ### gblinear\n",
    "    linear_params_opt = {'objective': 'reg:linear', 'booster': 'gblinear', 'random_state': 42,\n",
    "                     'updater': 'shotgun', 'feature_selector': 'cyclic', 'alpha': 0, 'lambda': 99}\n",
    "    gbll.append(regr_r2(xgb.XGBRegressor(**linear_params_opt), reduced_trainX, np.log(yt), reduced_validX, np.log(y1v)))\n",
    "    gbll2.append(regr_r2(xgb.XGBRegressor(**linear_params_opt), tX_interact, np.log(yt), vX_interact, np.log(y1v)))\n",
    "    print('gblinear:', gbll[-1], gbll2[-1])\n",
    "    \n",
    "    ### gbtree\n",
    "    tree_params_opt = {'objective': 'reg:linear', 'booster': 'gbtree', 'random_state': 42,\n",
    "              'subsample': 0.85, 'eta': 0.09, 'lambda': 0.1, 'min_child_weight': 75}\n",
    "    gbtl.append(regr_r2(xgb.XGBRegressor(**tree_params_opt), reduced_trainX, np.log(yt), reduced_validX, np.log(y1v)))\n",
    "    gbtl2.append(regr_r2(xgb.XGBRegressor(**tree_params_opt), tX_interact, np.log(yt), vX_interact, np.log(y1v)))\n",
    "    print('gbtree:', gbtl[-1], gbtl2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储结果\n",
    "regr_df = pd.DataFrame({'PCA': pca_range,\n",
    "                       'ridge': ridgel,\n",
    "                       'ridge_i': ridgel2,\n",
    "                       'lasso': lassol,\n",
    "                       'lasso_i': lassol2,\n",
    "                       'rf': rfl,\n",
    "                       'rf_i': rfl2,\n",
    "                       'gblinear': gbll,\n",
    "                       'gblinear_i': gbll2,\n",
    "                       'gbtree': gbtl,\n",
    "                       'gbtree_i': gbtl2})\n",
    "regr_df.to_csv('Result/regr3-25_aug.csv', index = False, header = True)\n",
    "print(regr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
